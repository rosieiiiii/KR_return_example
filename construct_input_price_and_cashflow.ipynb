{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NOWOXd1WMrK8"
   },
   "source": [
    "- This notebook reads processed CRSP Treasury data files given by `get_and_select_raw_data.ipynb` and generates price vectors and cashflow matrices.\n",
    "- We follow Gurkaynak, Sack, and Wright (2007) and Liu and Wu (2021) and exclude the two most recently issued securities with maturities of 2, 3, 4, 5, 7, 10, 20, and 30 years for securities issued in 1980 or later.\n",
    "- Price vectors and cashflow matrices are generated only for dates in between start_date and end_date (inclusive). If the number of time periods is large (e.g. > 10,000 days), export this notebook into .py file and run the .py file instead to accelerate computation.\n",
    "- Cashflow matrices are saved in compressed form separately for each date, while price vectors are exported in a dataframe with date index.\n",
    "- Calculate time to coupon payment as the time to ACTUAL payment i.e. (TDPDINT!=0), not according to scheduled payment date, which can be on weekend\n",
    "- Additional selection criterion:\n",
    "  - security whose time-t price and return from t to t+1 are available\n",
    "  - maturing within 10 years\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "_aNzGTJXMrLA"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse as sps\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "from datetime import datetime\n",
    "from pandas.tseries.offsets import *\n",
    "%matplotlib inline\n",
    "from itertools import groupby\n",
    "import pickle\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "bj0SG0m2MrLC"
   },
   "outputs": [],
   "source": [
    "save_to_pickle = True\n",
    "generate_C = True\n",
    "mat_day = 3650 #time to maturity maturity cutoff\n",
    "\n",
    "# where to save formatted data\n",
    "dir_output = './B_and_C/' \n",
    "# where to save B mat and date lookup tables\n",
    "dir_B = dir_output+'B_max_ttm_10yr/'\n",
    "# where to save C's\n",
    "npz_dir = dir_output+'npz_C/'\n",
    "\n",
    "if not os.path.exists(dir_output):\n",
    "    os.mkdir(dir_output)\n",
    "if not os.path.exists(dir_B):\n",
    "    os.mkdir(dir_B)\n",
    "if not os.path.exists(npz_dir):\n",
    "    os.mkdir(npz_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WnNFEYzeMrLD"
   },
   "source": [
    "# Load selected data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "gg5LwMDrMrLD"
   },
   "outputs": [],
   "source": [
    "dir_tfz = './processed_data/'\n",
    "df_info_dly = pd.read_pickle(dir_tfz + 'df_info_dly_s.pkl')\n",
    "df_dly = pd.read_pickle(dir_tfz + 'df_dly_s.pkl')\n",
    "df_nomprc = pd.read_pickle(dir_tfz + 'df_nomprc_s.pkl')\n",
    "df_tdaccint = pd.read_pickle(dir_tfz + 'df_tdaccint_s.pkl')\n",
    "df_tdretnua = pd.read_pickle(dir_tfz + 'df_tdretnua_s.pkl')\n",
    "df_tdpdint = pd.read_pickle(dir_tfz + 'df_tdpdint_s.pkl')\n",
    "# shift date of daily return s.t. return from [t,t+1] is aligned at t\n",
    "df_tdretnua_shift = df_tdretnua.shift(-1,axis=0)\n",
    "\n",
    "df_pay = pd.read_pickle(dir_tfz + 'df_pay_s.pkl')\n",
    "df_B = pd.read_pickle(dir_tfz + 'df_B_s.pkl')\n",
    "df_Bc = pd.read_pickle(dir_tfz + 'df_Bc_s.pkl')\n",
    "\n",
    "# shift date of Bc s.t. Bc at t+1 is aligned at t\n",
    "df_Bc_shift = df_Bc.shift(-1, axis=0)\n",
    "df_B_shift = df_B.shift(-1, axis=0)\n",
    "\n",
    "df_nomprc_bin =~ df_nomprc.isnull()\n",
    "df_tdretnua_bin =~ df_tdretnua_shift.isnull()\n",
    "\n",
    "num_kytreasno = len(df_nomprc.columns)\n",
    "nmax = df_nomprc_bin.sum(axis=1).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "V-ou6dxuMrLE"
   },
   "outputs": [],
   "source": [
    "assert df_B.index.equals(df_nomprc.index)\n",
    "assert (df_B.columns == df_nomprc.columns).all()\n",
    "df_B_bin =~ df_B.isnull()\n",
    "assert (df_B_bin == df_nomprc_bin).all().all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K8sstv-jMrLE"
   },
   "source": [
    "# Get lookup table between t:0 to T-1 and dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "QLXsAj5lMrLF",
    "outputId": "621050b9-989a-44f7-985b-b703515c8309",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15367"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "T = len(df_nomprc_bin.index)\n",
    "display(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Eyvzn3YHMrLG",
    "outputId": "717c434b-956a-44b4-f573-401b31984e77"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1961-06-14</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1961-06-15</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1961-06-16</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1961-06-19</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1961-06-20</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            t\n",
       "1961-06-14  0\n",
       "1961-06-15  1\n",
       "1961-06-16  2\n",
       "1961-06-19  3\n",
       "1961-06-20  4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1961-06-30</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1961-07-31</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1961-08-31</th>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1961-09-29</th>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1961-10-31</th>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             t\n",
       "date          \n",
       "1961-06-30  12\n",
       "1961-07-31  32\n",
       "1961-08-31  55\n",
       "1961-09-29  75\n",
       "1961-10-31  96"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### daily lookup\n",
    "df_t_lookup = pd.DataFrame(index=df_nomprc.index,\\\n",
    "                         data=np.arange(0,T),columns=['t'])\n",
    "\n",
    "display(df_t_lookup.head())\n",
    "\n",
    "### monthly lookup\n",
    "df_t_lookup['date'] = df_t_lookup.index\n",
    "df_t_lookup_monthly = df_t_lookup\\\n",
    "    .groupby(by=[df_t_lookup.index.month, df_t_lookup.index.year]).max()\\\n",
    "    .reset_index()[['t','date']]\\\n",
    "    .set_index('date')\\\n",
    "    .sort_index()\n",
    "df_t_lookup = df_t_lookup.drop(['date'], axis=1)\n",
    "\n",
    "display(df_t_lookup_monthly.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dkaYq8EEMrLH"
   },
   "source": [
    "# Get dataframe of time to maturity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "e70020dc8f9643b88de9306509bba415"
     ]
    },
    "id": "v5G9W1wPMrLH",
    "outputId": "bda3e647-d5b1-47e5-9731-e173063d005f"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44560d9566214164a4c7a6ca259cbb4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5749 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_ttm = pd.DataFrame(index=df_nomprc.index)\n",
    "pbar = tqdm(total=len(df_info_dly))\n",
    "\n",
    "#fill df_ttm\n",
    "for i in range(0, len(df_info_dly)):\n",
    "    kytreasno = df_info_dly.iloc[i].KYTREASNO\n",
    "    maturity_date = df_info_dly.iloc[i].TMATDT\n",
    "    issue_date = df_info_dly.iloc[i].TDATDT\n",
    "    time_to_maturity = (maturity_date-df_ttm.index).days\n",
    "    #time_since_issue=(df_ttm.index-issue_date).days\n",
    "    \n",
    "    temp_ttm = (maturity_date-df_ttm.index).days.values.astype(np.float)\n",
    "    # mark ttm of securities that have matured as 0\n",
    "    temp_ttm[temp_ttm<0] = np.nan\n",
    "    # mark ttm of securities that haven't been issued as 0\n",
    "    temp_ttm[df_ttm.index<issue_date] = np.nan\n",
    "    \n",
    "    df_ttm[kytreasno] = temp_ttm#(maturity_date-df_ttm.index).days\n",
    "    \n",
    "    pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "KVw3Q0leMrLI",
    "outputId": "8539a867-8440-4788-8ad1-66d38505895b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of missing obs: 1027298\n"
     ]
    }
   ],
   "source": [
    "# check if we have price and return data for all securities with >ttm_tgt days to maturity\n",
    "# not the case\n",
    "ttm_tgt = 7\n",
    "df_mask = df_ttm>ttm_tgt\n",
    "\n",
    "# check if observations with True in df_mask are also True in df_nomprc_bin\n",
    "temp = df_nomprc_bin.values[df_mask.values]\n",
    "num_missing = (~temp).sum()\n",
    "# \n",
    "print('number of missing obs: {}'.format(num_missing))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Se76BmVTMrLJ"
   },
   "source": [
    "# Generate cashflow matrix\n",
    "### For each date select bonds whose ttm is in (0,mat_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "mV5yc3I-MrLJ",
    "outputId": "f22cea4a-707c-4bbf-bfcc-cc77fb16aa92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mat_day cutoff:3650\n",
      "generate_C:True\n",
      "T:15367\n",
      "nmax:384\n",
      "num_kytreasno:5749\n",
      "t=0 date:1961-06-14 00:00:00\n",
      "t=T-1 date:2022-12-30 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# selection criterion:\n",
    "# taxable and non-flower \n",
    "# security whose time-t price and return from t to t+1 are available\n",
    "# maturing within 10 years\n",
    "print('mat_day cutoff:{}'.format(mat_day))\n",
    "print('generate_C:{}'.format(generate_C))\n",
    "print('T:{}'.format(T))\n",
    "print('nmax:{}'.format(nmax))\n",
    "print('num_kytreasno:{}'.format(num_kytreasno))\n",
    "print('t=0 date:{}'.format(df_nomprc.index[0]))\n",
    "print('t=T-1 date:{}'.format(df_nomprc.index[-1]))\n",
    "\n",
    "prefix_C = 'C_10yr_'\n",
    "Nmax_C = mat_day + 1 #the first col of C mat is 0 for convenience, will remove\n",
    "removal_maturities = [2, 3, 4, 5, 7, 10, 20, 30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "N6c8ASBRMrLJ"
   },
   "outputs": [],
   "source": [
    "# generate a dictionary of parameters and save it\n",
    "dict_par = {'T':T, 'Nmax':mat_day, 'Nmax_C':Nmax_C, 'nmax':nmax,\\\n",
    "            't0':df_nomprc.index[0], 'tT-1':df_nomprc.index[-1],\\\n",
    "            'num_kytreasno':num_kytreasno, 'prefix_C':prefix_C, 'npz_dir':npz_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "_NvWSa9dMrLJ",
    "outputId": "5a96630f-43fa-4068-d877-0a65e4add55d"
   },
   "outputs": [],
   "source": [
    "# save date look-up table and dict_par\n",
    "if save_to_pickle:\n",
    "    df_t_lookup.to_pickle(dir_B + 'df_t_lookup_daily.pkl')\n",
    "    df_t_lookup_monthly.to_pickle(dir_B + 'df_t_lookup_monthly.pkl')\n",
    "    \n",
    "    with open(dir_B + 'dict_par.pkl','wb') as handle:\n",
    "        pickle.dump(dict_par,handle,protocol=pickle.HIGHEST_PROTOCOL)\n",
    "else:\n",
    "    print('not saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "27504e509f8a41e7a6611df1f2c4d581"
     ]
    },
    "id": "2PsdpImmMrLK",
    "outputId": "401bdb6d-a6e9-44f5-c93f-884c504f73c1"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4907fa891eae48c198f128a1d47f4863",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15367 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#if save_to_pickle, WILL SAVE B_mat, ret_mat, ttm_day_mat AT THE END OF THIS BLOCK\n",
    "B_mat = np.zeros([nmax,T])\n",
    "Bc_shift_mat = np.zeros([nmax,T])\n",
    "B_shift_mat = np.zeros([nmax,T])\n",
    "ret_mat = np.full([nmax,T],np.nan) # aligned with B_mat\n",
    "tdaccint_mat = np.full([nmax,T],np.nan) # aligned with B_mat\n",
    "kytreasno_mat = np.full([nmax,T],np.nan) # aligned with B_mat\n",
    "num_rm_on_the_run = np.zeros(T)\n",
    "\n",
    "\n",
    "dict_B_kytreasno = dict() # track kytreasno used in B_mat and ret_mat\n",
    "ttm_day_mat = np.full([nmax,T],np.nan) # track ttm in days, aligned with B_mat\n",
    "\n",
    "pbar = tqdm(total=T)\n",
    "for t in range(T):   \n",
    "    #find kytreasno whose ttm is between (0, mat_day]\n",
    "    df_ttm_slice = df_ttm.iloc[t]\n",
    "    today = df_ttm_slice.name\n",
    "    arr_kytreasno = df_ttm_slice[(df_ttm_slice>0)&(df_ttm_slice<=mat_day)].index.values\n",
    "\n",
    "    #get B \n",
    "    srs_B = df_B.iloc[t][arr_kytreasno]\n",
    "    srs_Bc_shift = df_Bc_shift.iloc[t][arr_kytreasno]\n",
    "    srs_B_shift = df_B_shift.iloc[t][arr_kytreasno]\n",
    "    #remove prices that are nan, this happen if bond has not been issued\n",
    "    set_kytreasno_B = set(srs_B[~srs_B.isnull()].index)\n",
    "    \n",
    "    # get tdaccint\n",
    "    srs_tdaccint = df_tdaccint.iloc[t][arr_kytreasno]\n",
    "\n",
    "    # get return from t to t+1\n",
    "    srs_ret = df_tdretnua_shift.iloc[t][arr_kytreasno]\n",
    "    srs_ret[~srs_ret.isnull()].index\n",
    "    set_kytreasno_ret = set(srs_ret[~srs_ret.isnull()].index)\n",
    "\n",
    "    # list of kytreasno to use for time t\n",
    "    lst_kytreasno = list(set_kytreasno_B.intersection(set_kytreasno_ret))\n",
    "    \n",
    "    \n",
    "    ## Exclude the two most recently issued securities with \n",
    "    # maturities of 2, 3, 4, 5, 7, 10, 20, and 30 years for securities issued in 1980 or later.\n",
    "    \n",
    "    if today >= pd.to_datetime('1980-01-01'):\n",
    "        remove_on_the_run = True\n",
    "    else:\n",
    "        remove_on_the_run = False\n",
    "\n",
    "    if remove_on_the_run:\n",
    "        df_info_slice = df_info_dly[df_info_dly.KYTREASNO.isin(lst_kytreasno)]\n",
    "        lst_kytreasno_rm = []\n",
    "        for maturity in removal_maturities:\n",
    "            df_temp = df_info_slice[df_info_slice.RoundedMaturityYears==maturity]\n",
    "            lst_kytreasno_rm.extend(list(df_temp.sort_values(by='TDATDT',ascending=False).iloc[:2].KYTREASNO.values))\n",
    "        num_rm = len(lst_kytreasno_rm)\n",
    "        lst_kytreasno = list(set(lst_kytreasno).difference(set(lst_kytreasno_rm)))\n",
    "    else:\n",
    "        num_rm = 0\n",
    "    num_rm_on_the_run[t] = num_rm\n",
    "\n",
    "\n",
    "\n",
    "    srs_B = srs_B.loc[lst_kytreasno]\n",
    "    srs_Bc_shift = srs_Bc_shift.loc[lst_kytreasno]\n",
    "    srs_B_shift = srs_B_shift.loc[lst_kytreasno]\n",
    "    srs_ret = srs_ret.loc[lst_kytreasno]\n",
    "    srs_tdaccint = srs_tdaccint.loc[lst_kytreasno]\n",
    "\n",
    "    assert (srs_B.index==srs_ret.index).all()\n",
    "    assert (srs_B.index==srs_Bc_shift.index).all()\n",
    "    assert (srs_B.index==srs_B_shift.index).all()\n",
    "    assert (srs_B.index==srs_tdaccint.index).all()\n",
    "    num_prc=len(srs_B)\n",
    "\n",
    "    #fill B_mat , ret_mat\n",
    "    B_mat[0:num_prc, t] = srs_B.values\n",
    "    Bc_shift_mat[0:num_prc, t] = srs_Bc_shift.values\n",
    "    B_shift_mat[0:num_prc, t] = srs_B_shift.values\n",
    "    ret_mat[0:num_prc, t] = srs_ret.values\n",
    "    tdaccint_mat[0:num_prc, t] = srs_tdaccint.values\n",
    "    kytreasno_mat[0:num_prc, t] = lst_kytreasno\n",
    "    \n",
    "    dict_B_kytreasno[t] = lst_kytreasno\n",
    "\n",
    "    if generate_C:\n",
    "        #fill C\n",
    "        #get payment\n",
    "        df_pay_valid_temp = df_pay[df_pay.KYTREASNO.isin(srs_B.index)]\n",
    "        #assume a storage is given\n",
    "        arr_C_temp = np.zeros([nmax,Nmax_C])\n",
    "        # need to discard firsr col of arr_C_temp because no payment due today\n",
    "        # where (timediff=0)   \n",
    "        for i, kytreasno in enumerate(srs_B.index):\n",
    "            #slice payment info corresponding to kytreasno\n",
    "            df_pay_kytreasno_temp = df_pay_valid_temp\\\n",
    "            [df_pay_valid_temp.KYTREASNO==kytreasno]\n",
    "\n",
    "            # calculate time to coupon payment as the time to ACTUAl payment \n",
    "            # i.e. (TDPDINT!=0), not according to scheduled payment date, which can be on weekend\n",
    "            \n",
    "            # get ACTUAL coupon payment dates\n",
    "            df_slice = df_dly[df_dly.KYTREASNO==kytreasno][['CALDT','TDPDINT']]\n",
    "            df_slice = df_slice[df_slice.TDPDINT!=0]\n",
    "            # get the last coupon payment dates (i.e. maturity) when price quote ends\n",
    "            if len(df_slice) > 0:\n",
    "                df_slice_1 = df_pay_kytreasno_temp[df_pay_kytreasno_temp.TPQDATE<df_slice.CALDT.min()]\n",
    "                df_slice_2 = df_pay_kytreasno_temp[df_pay_kytreasno_temp.TPQDATE>df_slice.CALDT.max()]\n",
    "            else:\n",
    "                df_slice_1 = None\n",
    "                df_slice_2 = df_pay_kytreasno_temp[df_pay_kytreasno_temp.TPQDATE>=df_t_lookup.index[0]]\n",
    "            df_slice_2 = df_slice_2[['TPQDATE','PDINT']]\n",
    "            df_slice_2.columns = df_slice.columns\n",
    "            # merge\n",
    "            df_slice = pd.concat((df_slice,df_slice_2),ignore_index=True)\n",
    "            # check no missing coupon payment dates\n",
    "            if len(df_pay_kytreasno_temp[df_pay_kytreasno_temp.TPQDATE>=df_t_lookup.index[0]])!=len(df_slice):\n",
    "                if len(df_slice_1) > 0:\n",
    "                    df_slice_1 = df_slice_1[['TPQDATE','PDINT']]\n",
    "                    df_slice_1.columns = df_slice.columns\n",
    "                    df_slice = pd.concat((df_slice,df_slice_1),ignore_index=True)\n",
    "                assert len(df_pay_kytreasno_temp[df_pay_kytreasno_temp.TPQDATE>=df_t_lookup.index[0]])==len(df_slice)\n",
    "            df_slice.sort_values(by='CALDT', inplace=True)\n",
    "            \n",
    "            # fill C\n",
    "            # calculate time left to coupon payment\n",
    "            time_to_coupon_temp = df_slice.CALDT - today\n",
    "            arr_day_to_coupon = time_to_coupon_temp.values.astype('timedelta64[D]').astype('int16')\n",
    "            # add upcoming coupon payment to cashflow matrix\n",
    "            # do not record cashflow today        \n",
    "            arr_day_to_coupon_pos = arr_day_to_coupon[arr_day_to_coupon>0]\n",
    "            arr_C_temp[i,arr_day_to_coupon_pos] = df_slice[arr_day_to_coupon>0].TDPDINT.values\n",
    "            # time to maturity\n",
    "            day_to_mat = (df_info_dly[df_info_dly.KYTREASNO==kytreasno].TMATDT-today).\\\n",
    "                values.astype('timedelta64[D]').astype('int16')\n",
    "            # sanity check\n",
    "            if len(arr_day_to_coupon) > 0: # coupon bond\n",
    "                assert arr_day_to_coupon[-1]==day_to_mat\n",
    "            ttm_day_mat[i,t] = day_to_mat\n",
    "            #add face value payment\n",
    "            arr_C_temp[i,day_to_mat] += 100     \n",
    "            \n",
    "        # the next cash flow should be on t+date_s. No cashflow in between by construction\n",
    "        if t < T-1:\n",
    "            date_s = (df_t_lookup.index[t+1]-df_t_lookup.index[t]).days\n",
    "            assert arr_C_temp[:num_prc,1:][:,:date_s-1].sum()==0\n",
    "            \n",
    "        #convert to csr format and save to npz file\n",
    "        csr_mat_temp = sps.csr_matrix(arr_C_temp)\n",
    "        npz_filename = prefix_C + 'C_' + str(t) + '.npz'\n",
    "        sps.save_npz(npz_dir + npz_filename, csr_mat_temp)\n",
    "        \n",
    "    pbar.update(1)\n",
    "    \n",
    "\n",
    "if save_to_pickle:\n",
    "    np.save(dir_B + 'B_mat.npy', B_mat)\n",
    "    np.save(dir_B + 'Bc_shift_mat.npy', Bc_shift_mat)\n",
    "    np.save(dir_B + 'B_shift_mat.npy', B_shift_mat)\n",
    "    np.save(dir_B + 'ret_mat.npy', ret_mat)\n",
    "    np.save(dir_B + 'tdaccint_mat.npy', tdaccint_mat)\n",
    "    np.save(dir_B + 'kytreasno_mat.npy', kytreasno_mat)\n",
    "    np.save(dir_B + 'ttm_day_mat.npy', ttm_day_mat)\n",
    "    with open(dir_B + 'dict_B_kytreasno.pkl', 'wb') as handle:\n",
    "        pickle.dump(dict_B_kytreasno, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "else:\n",
    "    print('not saved')      "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
